{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28d2a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "746eb77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnTreeVB.data import evolve_seqs_full_homogeneity                                              \n",
    "from nnTreeVB.data import build_tree_from_nwk\n",
    "from nnTreeVB.data import SeqCollection\n",
    "from nnTreeVB.data import build_msa_categorical\n",
    "\n",
    "from nnTreeVB.models import VB_nnTree\n",
    "# from nnTreeVB.models.vb_models.vb_nntree import VB_nnTree\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import copy\n",
    "from pprint import pprint\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.ticker as ticker\n",
    "\n",
    "# import logomaker as lm\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "torch.set_printoptions(precision=4, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5208b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b2574d",
   "metadata": {},
   "source": [
    "## Alignment simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd22d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4323829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evolving new sequences with the amazing Pyvolve for None\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "alignment_len = 1000\n",
    "\n",
    "str_tree = \"(((1:0.3,2:0.7)N1:0.15,3:0.2)N2:0.1,4:0.4);\"\n",
    "# str_tree = \"(((tx1:0.3,tx2:0.7)N1:0.15,tx3:0.2)N2:0.1,tx4:0.4);\"\n",
    "# str_tree = \"(tx2:1.0411,tx4:0.8121,(tx1:1.1242,tx3:0.9130)N1:1.1095);\"\n",
    "# str_tree = \"((1:0.3,2:0.7)N1:0.15,3:0.2,4:0.4);\"\n",
    "# str_tree = \"((tx2:0.3,tx1:0.7)N1:0.15,tx3:0.2);\"\n",
    "# str_tree = \"(1:0.1,2:0.2,3:0.3,4:0.4);\"\n",
    "\n",
    "#            \"AG\"  \"AC\"  \"AT\"  \"GC\"  \"GT\" \"CT\"\n",
    "sim_rates = [0.16, 0.05, 0.16, 0.09, 0.3, 0.24]\n",
    "evo_rates = [0.16, 0.05, 0.16, 0.09, 0.3, 0.24]\n",
    "\n",
    "#             A     C    G     T\n",
    "sim_freqs = [0.1, 0.45, 0.3, 0.15]\n",
    "#             A     G    C     T\n",
    "evo_freqs = [0.1, 0.3, 0.45, 0.15]\n",
    "\n",
    "\n",
    "ete_tree, taxa, nodes = build_tree_from_nwk(str_tree)\n",
    "logl_tree = copy.copy(ete_tree)\n",
    "\n",
    "all_seqdict = evolve_seqs_full_homogeneity(\n",
    "        str_tree,\n",
    "        fasta_file=None,\n",
    "        nb_sites=alignment_len,\n",
    "        subst_rates=sim_rates,\n",
    "        state_freqs=sim_freqs,\n",
    "        return_anc=True,\n",
    "        verbose=verbose)\n",
    "\n",
    "sequences = [all_seqdict[s] for s in taxa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f39b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "# # device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b6ebd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequencies\n",
      "tensor([0.1000, 0.3000, 0.4500, 0.1500])\n",
      "tensor(1.)\n",
      "\n",
      "Relative rates\n",
      "tensor([0.1600, 0.0500, 0.1600, 0.0900, 0.3000, 0.2400])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "gtr_freqs = torch.tensor(evo_freqs)\n",
    "print(\"\\nFrequencies\")\n",
    "print(gtr_freqs)\n",
    "print(gtr_freqs.sum())\n",
    "\n",
    "gtr_rates = torch.tensor(evo_rates) # AG, AC, AT, GC, GT, CT\n",
    "print(\"\\nRelative rates\")\n",
    "print(gtr_rates)\n",
    "print(gtr_rates.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608cc491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "true_branches\n",
      "tensor([[0.3000],\n",
      "        [0.7000],\n",
      "        [0.2000],\n",
      "        [0.4000],\n",
      "        [0.1500],\n",
      "        [0.1000]])\n",
      "tensor(1.8500)\n"
     ]
    }
   ],
   "source": [
    "true_branches = torch.zeros(len(ete_tree.get_descendants()))\n",
    "# print(true_branches.shape[0])\n",
    "\n",
    "for node in ete_tree.traverse(\"postorder\"):\n",
    "\n",
    "    if node.rank < true_branches.shape[0]:\n",
    "#         print(node.name, node.rank, node.dist)\n",
    "        true_branches[node.rank] = node.dist\n",
    "\n",
    "true_branches = true_branches.unsqueeze(-1)\n",
    "print(\"\\ntrue_branches\")\n",
    "print(true_branches)\n",
    "print(true_branches.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "728e20bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_branches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dbfde6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([178, 4, 4])\n",
      "tensor([  4,   5,   1,   5,   3,   2,   5,   1,   1,  15,   4,   1,   2,  14,\n",
      "          5,   1,   6,   3,   5,   1,   3,   4,   3,   4,   1,   2,   8,   4,\n",
      "          2,   6,   2,   9,   1,   2,   1,   2,   1,   1,   1,   2,   1,   1,\n",
      "          1,   2,   1,   6,   3,   2,  37,   2,   3,   4,   2,   2,   1,   3,\n",
      "         15,  14,   1,  14, 175,  20,   2,   3,  14,  12,   2,   5,   1,   1,\n",
      "          2,   2,   4,   4,  27,   6,   1,   6,   5,  14,   5,   2,   3,   1,\n",
      "          1,   7,   1,   1,   1,   1,   1,   1,   3,   2,   1,   1,   7,   1,\n",
      "          1,   3,   7,  17,   1,   1,   3,   2,   4,   1,   2,  14,  12,   2,\n",
      "          5,  11,  24,   1,   2,   3,   6,   8,   6,   3,  10,   7,   1,  13,\n",
      "         18,  73,   9,   2,   1,   3,   2,   1,   1,   2,   1,   1,   5,   6,\n",
      "          1,   3,   1,   1,   1,   1,   2,   4,   4,   1,   3,   1,   1,   1,\n",
      "          3,   1,   1,   1,   5,   1,   2,   1,   1,   1,   1,   3,   1,   1,\n",
      "          2,  13,   1,   1,   3,   1,   3,   2,   5,  22])\n"
     ]
    }
   ],
   "source": [
    "motifs_cats = build_msa_categorical(sequences)\n",
    "X = torch.from_numpy(motifs_cats.data)\n",
    "V = X.clone().detach()\n",
    "V_counts = torch.ones(V.shape[0]).detach()\n",
    "# X_counts = torch.ones(X.shape[0])\n",
    "X, X_counts = X.unique(dim=0, return_counts=True)\n",
    "\n",
    "print(X.shape)\n",
    "print(X_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd47ba5",
   "metadata": {},
   "source": [
    "## True log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b47d583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3992.7161)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nnTreeVB.models.evo_models import pruning\n",
    "from nnTreeVB.models.evo_models import build_GTR_transition_matrix\n",
    "\n",
    "tm = build_GTR_transition_matrix(true_branches.unsqueeze(0), \n",
    "                                 gtr_rates.unsqueeze(0), \n",
    "                                 gtr_freqs.unsqueeze(0))\n",
    "\n",
    "true_lls = (pruning(logl_tree, X.unsqueeze(0), tm, gtr_freqs.unsqueeze(0)) * X_counts).sum()\n",
    "true_lls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d4e866",
   "metadata": {},
   "source": [
    "## nnTreeVB model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc7aa8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "seed = 7353453\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "x_dim = 4\n",
    "# Number of sequences\n",
    "m_dim = len(ete_tree.get_leaf_names())\n",
    "# Number of internal nodes\n",
    "a_dim = len(ete_tree.get_descendants()) - m_dim + 1\n",
    "# Number of branches\n",
    "b_dim = len(ete_tree.get_edges()) - 1\n",
    "\n",
    "h_dim = 32\n",
    "nb_layers = 3\n",
    "\n",
    "ancestor_prior_hp = (torch.ones(4)/4).tolist()\n",
    "# ancestor_prior_hp = torch.tensor([f_A, f_G, f_C, f_T])\n",
    "\n",
    "# branch_prior_hp = torch.tensor([0.1, 0.1])\n",
    "# branch_prior_hp = torch.tensor([0.1, 1.])\n",
    "branch_prior_hp = [0.1]*b_dim\n",
    "\n",
    "# branch_prior_hp = torch.tensor(get_lognorm_params(0.01, 0.01))\n",
    "# branch_prior_hp = torch.tensor(get_lognorm_params(*compute_branch_mean_std(b_str)))\n",
    "\n",
    "tl_prior_hp = torch.tensor([1., 1.]).tolist()\n",
    "\n",
    "kappa_prior_hp = torch.tensor([0.1, 0.1]).tolist()\n",
    "\n",
    "rates_prior_hp = torch.ones(6).tolist() # Dirichlet\n",
    "# rates_prior_hp = torch.ones(6)/6 # Cat\n",
    "# rates_prior_hp = torch.tensor([m_AG, m_AC, m_AT, m_CG, m_GT, m_CT]) # AG, AC, AT, GC, GT, CT\n",
    "freqs_prior_hp = torch.ones(4).tolist() # Dirichlet\n",
    "# freqs_prior_hp = torch.tensor([f_A, f_G, f_C, f_T])\n",
    "\n",
    "# alpha_kl = 0.0001\n",
    "print(m_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3514b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "evoModel = VB_nnTree(\n",
    "    x_dim,\n",
    "    m_dim,\n",
    "    b_dim,\n",
    "    a_dim,\n",
    "    subs_model=\"gtr\",  # jc69 | k80 | hky | gtr\n",
    "    predict_ancestors=False,\n",
    "    \n",
    "#     # branch lengths follows gamma\n",
    "#     b_encoder_type=\"gamma_ind\",\n",
    "#     b_init_distr=[0.1, 0.1],\n",
    "#     b_hp=branch_prior_hp,\n",
    "\n",
    "#     # branch lengths fixed\n",
    "#     b_encoder_type=\"fixed\",\n",
    "#     b_init_distr=true_branches.detach(),\n",
    "\n",
    "    ## Compound branch lengths\n",
    "    b_encoder_type=\"dirichlet_ind\",\n",
    "    b_init_distr=[1.]*b_dim,\n",
    "    b_hp=branch_prior_hp,\n",
    "    # Tree lengths\n",
    "#     t_encoder_type=\"gamma_ind\",\n",
    "#     t_init_distr=[1., 1.],\n",
    "#     t_hp=tl_prior_hp,\n",
    "\n",
    "    # Tree length fixed\n",
    "    t_encoder_type=\"fixed\",\n",
    "    t_init_distr=torch.tensor([1.85]),\n",
    "    \n",
    "    # kappa\n",
    "#     k_encoder_type=\"gamma_nn_ind\",\n",
    "#     k_init_distr=[1., 0.1],\n",
    "#     k_hp=kappa_prior_hp,\n",
    "    \n",
    "#     k_encoder_type=\"fixed\",\n",
    "#     k_init_distr=torch.tensor([1.5]),\n",
    "    \n",
    "    # rates\n",
    "    r_encoder_type=\"dirichlet_ind\",\n",
    "    r_init_distr=[0.1]*6,\n",
    "    r_hp=rates_prior_hp,\n",
    "    \n",
    "    # frequencies\n",
    "    f_encoder_type=\"dirichlet_ind\",\n",
    "    f_init_distr=[1.]*4,\n",
    "    f_hp=freqs_prior_hp,\n",
    "\n",
    "#     f_encoder_type=\"fixed\",\n",
    "#     f_init_distr=gtr_freqs.detach(),\n",
    "\n",
    "    #\n",
    "    h_dim=h_dim,\n",
    "    nb_layers=nb_layers,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "95af4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting parameters\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.0005\n",
    "weight_decay = 0.000001\n",
    "\n",
    "nb_samples = 100\n",
    "sample_temp=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a9c02",
   "metadata": {},
   "source": [
    "## nnTreeVB model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "089022ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s\t Train Epoch: 20 \t ELBO: -7245.417\t Lls -7212.325\t KLs 35262.516\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter concentration (Tensor of shape (6,)) of distribution Dirichlet(concentration: torch.Size([6])) to satisfy the constraint IndependentConstraint(GreaterThan(lower_bound=0.0), 1), but found invalid values:\ntensor([nan, nan, nan, nan, nan, nan], grad_fn=<ExpBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [84]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mevoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mete_tree\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatent_sample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptim_learning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptim_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_fit_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Thesis/Software/nnTreeVB/nnTreeVB/models/vb_models/__init__.py:125\u001b[0m, in \u001b[0;36mBaseTreeVB.fit\u001b[0;34m(self, tree, X_train, X_train_counts, latent_sample_size, sample_temp, max_iter, optim, optim_learning_rate, optim_weight_decay, X_val, X_val_counts, A_val, keep_fit_history, keep_val_history, keep_fit_vars, keep_val_vars, verbose)\u001b[0m\n\u001b[1;32m    123\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m#try:\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m fit_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatent_sample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_sample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_temp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_temp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#alpha_kl=alpha_kl,\u001b[39;49;00m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle_sites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m elbos \u001b[38;5;241m=\u001b[39m fit_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melbo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    135\u001b[0m lls \u001b[38;5;241m=\u001b[39m fit_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogl\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/pyenvs/t111/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/Thesis/Software/nnTreeVB/nnTreeVB/models/vb_models/vb_nntree.py:242\u001b[0m, in \u001b[0;36mVB_nnTree.forward\u001b[0;34m(self, tree, sites, site_counts, elbo_type, latent_sample_size, sample_temp, shuffle_sites)\u001b[0m\n\u001b[1;32m    239\u001b[0m     ret_values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m a_samples\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# Sample b from q_d and compute log prior, log q\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m b_logprior, b_logq, b_kl, b_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_sample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mKL_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melbo_kl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m logprior \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m b_logprior\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    247\u001b[0m logq \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m b_logq\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/pyenvs/t111/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/Thesis/Software/nnTreeVB/nnTreeVB/models/vb_encoders/vb_dirichlet.py:62\u001b[0m, in \u001b[0;36mVB_Dirichlet_IndEncoder.forward\u001b[0;34m(self, sample_size, KL_gradient, min_clamp, max_clamp)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     56\u001b[0m         sample_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Approximate distribution\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist_q \u001b[38;5;241m=\u001b[39m \u001b[43mDirichlet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_alphas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Sample from approximate distribution q\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist_q\u001b[38;5;241m.\u001b[39mrsample(torch\u001b[38;5;241m.\u001b[39mSize([sample_size]))\n",
      "File \u001b[0;32m~/pyenvs/t111/lib/python3.10/site-packages/torch/distributions/dirichlet.py:52\u001b[0m, in \u001b[0;36mDirichlet.__init__\u001b[0;34m(self, concentration, validate_args)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcentration \u001b[38;5;241m=\u001b[39m concentration\n\u001b[1;32m     51\u001b[0m batch_shape, event_shape \u001b[38;5;241m=\u001b[39m concentration\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], concentration\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDirichlet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenvs/t111/lib/python3.10/site-packages/torch/distributions/distribution.py:55\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     53\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m---> 55\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     56\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28msuper\u001b[39m(Distribution, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter concentration (Tensor of shape (6,)) of distribution Dirichlet(concentration: torch.Size([6])) to satisfy the constraint IndependentConstraint(GreaterThan(lower_bound=0.0), 1), but found invalid values:\ntensor([nan, nan, nan, nan, nan, nan], grad_fn=<ExpBackward0>)"
     ]
    }
   ],
   "source": [
    "r = evoModel.fit(\n",
    "    copy.copy(ete_tree),\n",
    "    X, \n",
    "    X_counts,\n",
    "    latent_sample_size=nb_samples,\n",
    "    max_iter=n_epochs,\n",
    "    optim=\"adam\",\n",
    "    optim_learning_rate=learning_rate,\n",
    "    optim_weight_decay=weight_decay,\n",
    "    keep_fit_history=True,\n",
    "    verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = evoModel.sample(\n",
    "    ete_tree, \n",
    "    V, \n",
    "    V_counts,\n",
    "    latent_sample_size=nb_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3f9c4c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17812043 0.3619667  0.15700266 0.12714994 0.06660503 0.10915533]\n",
      "1.0000001\n"
     ]
    }
   ],
   "source": [
    "print(s[\"b\"].mean(0))\n",
    "print(s[\"b\"].mean(0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f84ff8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.32952273]\n",
      " [0.66963845]\n",
      " [0.29045495]\n",
      " [0.23522724]\n",
      " [0.12321934]\n",
      " [0.20193739]]\n",
      "1.8500001\n"
     ]
    }
   ],
   "source": [
    "print(s[\"bt\"].mean(0))\n",
    "print(s[\"bt\"].mean(0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28a31918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3000],\n",
      "        [0.7000],\n",
      "        [0.2000],\n",
      "        [0.4000],\n",
      "        [0.1500],\n",
      "        [0.1000]])\n",
      "tensor(1.8500)\n"
     ]
    }
   ],
   "source": [
    "print(true_branches)\n",
    "print(true_branches.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a83e316",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'r'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'r'"
     ]
    }
   ],
   "source": [
    "s[\"r\"].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eca20fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1600, 0.0500, 0.1600, 0.0900, 0.3000, 0.2400])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtr_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e33af564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10000002, 0.2999997 , 0.4500004 , 0.14999986], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"f\"].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7f9366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afad114e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t111",
   "language": "python",
   "name": "t111"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
